{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohLa_Bxc3SRR"
      },
      "source": [
        "# **Bibliotecas e Funções**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypcd8Bj7yUe2"
      },
      "source": [
        "## ***Bibliotecas***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhR3ojO0yUe4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# OpenCV\n",
        "import cv2\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "try:\n",
        "  import splitfolders\n",
        "except:\n",
        "  !pip install split-folders\n",
        "  import splitfolders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3VHWdLc3ah7"
      },
      "source": [
        "## ***Acessos Externos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7PQmqrCyUe7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ertFT1lWyUe7"
      },
      "source": [
        "## ***Download Dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_TPgb9yyUe8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!gdown --id 16qpj4czPFN4GXfTsbNH7hNYMz2LjLmf3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gypcWAyWyjsj"
      },
      "outputs": [],
      "source": [
        "!unrar x \"/content/covmingrad.rar\" \"/content/sample_data/treinamento/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkl-lGqQ2mFW"
      },
      "source": [
        "## ***Ajuste do Dataset***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Yy0VNAxzuje"
      },
      "source": [
        "### *Ajuste do tamanho das imagens*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiFidQBgwAR7"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/treinamento/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilXevr5heGkx"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "path = \"/content/sample_data/treinamento/non-logging/\"\n",
        "dirs = os.listdir( path )\n",
        "\n",
        "!mkdir \"/content/sample_data/treinamento/non-logging-resized/\"\n",
        "path2 = \"/content/sample_data/treinamento/non-logging-resized/\"\n",
        "dirs2 = os.listdir( path2 )\n",
        "\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(path2+item)\n",
        "            imResize = im.resize((50,50), Image.ANTIALIAS)\n",
        "            imResize.save(f + ' resized.tiff', 'tiff', quality=90)\n",
        "\n",
        "resize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rliQS3g4_mu"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "#!rm \"/content/treinamento/selective-pista/extrac_Id_1112.tif.aux.xml\"\n",
        "\n",
        "!rm \"/content/sample_data/treinamento/selective-logging/extrac_Id_1112.tif.aux.xml\"\n",
        "\n",
        "path = \"/content/sample_data/treinamento/selective-logging/\"\n",
        "dirs = os.listdir( path )\n",
        "\n",
        "!mkdir \"/content/sample_data/treinamento/selective-logging-resized/\"\n",
        "path2 = \"/content/sample_data/treinamento/selective-logging-resized/\"\n",
        "dirs2 = os.listdir( path2 )\n",
        "\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(path2+item)\n",
        "            imResize = im.resize((50,50), Image.ANTIALIAS)\n",
        "            imResize.save(f + ' resized.tiff', 'tiff', quality=90)\n",
        "\n",
        "resize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KEuu3gu2uQP"
      },
      "source": [
        "### *Transformação de .tiff para .jpg*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knjXEccU7YV6"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/sample_data/treinamento/train/\"\n",
        "!mkdir \"/content/sample_data/treinamento/train/non-logging-resized\"\n",
        "#yourpath = os.getcwd()\n",
        "yourpath = \"/content/sample_data/treinamento/non-logging-resized\"\n",
        "\n",
        "root1 = \"/content/sample_data/treinamento/non-logging-resized\"\n",
        "root2 = \"/content/sample_data/treinamento/train/non-logging-resized\"\n",
        "\n",
        "for root1, dirs, files in os.walk(yourpath, topdown=False):\n",
        "    for name in files:\n",
        "        print(os.path.join(root1, name))\n",
        "        if os.path.splitext(os.path.join(root1, name))[1].lower() == \".tiff\":\n",
        "            if os.path.isfile(os.path.splitext(os.path.join(root1, name))[0] + \".jpg\"):\n",
        "                print (\"A jpeg file already exists for %s\" % name)\n",
        "            # If a jpeg is *NOT* present, create one from the tiff.\n",
        "            else:\n",
        "                outfile = os.path.splitext(os.path.join(root2,name))[0] + \".jpg\"\n",
        "                try:\n",
        "                    im = Image.open(os.path.join(root1, name))\n",
        "                    print (\"Generating jpeg for %s\" % name)\n",
        "                    im.thumbnail(im.size)\n",
        "                    im.save(outfile, \"JPEG\", quality=100)\n",
        "                except (Exception, e):\n",
        "                    print (e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bQM0VtBQKMR"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/sample_data/treinamento/train/selective-loggin-resized/\"\n",
        "#yourpath = os.getcwd()\n",
        "yourpath = \"/content/sample_data/treinamento/selective-logging-resized\"\n",
        "\n",
        "root1 = \"/content/sample_data/treinamento/selective-logging-resized\"\n",
        "root2 = \"/content/sample_data/treinamento/train/selective-loggin-resized\"\n",
        "\n",
        "for root1, dirs, files in os.walk(yourpath, topdown=False):\n",
        "    for name in files:\n",
        "        print(os.path.join(root1, name))\n",
        "        if os.path.splitext(os.path.join(root1, name))[1].lower() == \".tiff\":\n",
        "            if os.path.isfile(os.path.splitext(os.path.join(root1, name))[0] + \".jpg\"):\n",
        "                print (\"A jpeg file already exists for %s\" % name)\n",
        "            # If a jpeg is *NOT* present, create one from the tiff.\n",
        "            else:\n",
        "                outfile = os.path.splitext(os.path.join(root2,name))[0] + \".jpg\"\n",
        "                try:\n",
        "                    im = Image.open(os.path.join(root1, name))\n",
        "                    print (\"Generating jpeg for %s\" % name)\n",
        "                    im.thumbnail(im.size)\n",
        "                    im.save(outfile, \"JPEG\", quality=100)\n",
        "                except (Exception, e):\n",
        "                    print (e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQXv6kE_2SNr"
      },
      "source": [
        "## ***Funções***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-kWhpSeRraI"
      },
      "source": [
        "## ***Ignorar Warnings***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DOJ2sA4Rr9t"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFE-RdapAWmW"
      },
      "source": [
        "# **Overview do Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9PP-r_pI-vC"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/sample_data/train&test\"\n",
        "!mkdir \"/content/sample_data/train&test/non-logging-resized\"\n",
        "\n",
        "input_folder = \"/content/sample_data/treinamento/train/\"\n",
        "output_folder = \"/content/sample_data/treinamento/train&test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgk0tACE0zNJ"
      },
      "outputs": [],
      "source": [
        "nrows = 3\n",
        "ncols = 10\n",
        "j = 0\n",
        "for path, dirs, files in os.walk(input_folder, topdown=False):\n",
        "  print(path)\n",
        "  if (len(files)>0):\n",
        "    plt.figure(figsize=(5*ncols,5*nrows))\n",
        "\n",
        "    for i in range(nrows*ncols):\n",
        "      n_img = random.randint(0, len(files))\n",
        "      img = Image.open(os.path.join(path, files[n_img]))\n",
        "\n",
        "      ax = plt.subplot(nrows, ncols, i+1)\n",
        "      ax.axis('off')\n",
        "      plt.imshow(img)\n",
        "\n",
        "    j +=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HfSSxLVCFfY"
      },
      "source": [
        "# **Preparação dos Dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yzSB3Y6Jwy4"
      },
      "source": [
        "## ***Split***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZBQzJcHCRI1"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio(input_folder, output_folder, seed=42, ratio=(.8, .1, .1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2chJryzfCUop"
      },
      "source": [
        "## ***Carregar e pré-processar as imagens***\n",
        "\n",
        "Retornará um tf.data.Datasetque produz lotes de imagens dos subdiretórios class_ae class_b, junto com os rótulos 0 e 1 (0 correspondendo a class_ae 1 correspondendo a class_b)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7El70uOGX4nX"
      },
      "outputs": [],
      "source": [
        "image_size = (50, 50)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/sample_data/treinamento/train&test/train\",\n",
        "    validation_split=.001,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1039Y3kiRwBV"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjH0BpF4JuLH"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/sample_data/treinamento/train&test/val\",\n",
        "    validation_split=.7,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaHWU0kpXV1z"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/sample_data/treinamento/train&test/test\",\n",
        "    validation_split=.3,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UiClYOPPHVD"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "val_ds = val_ds.prefetch(buffer_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztHR6tWL3gcY"
      },
      "source": [
        "# **Data Augmentation**\n",
        "\n",
        "Espelhamento, rotação, zoom\n",
        "\n",
        "- layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n",
        "- layers.experimental.preprocessing.RandomRotation(0.05)\n",
        "- layers.experimental.preprocessing.RandomZoom(0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve8aFrXrPAlH"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "     layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "     layers.experimental.preprocessing.RandomRotation(0.05),\n",
        "     layers.experimental.preprocessing.RandomZoom(0.10)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVNIDkgfPE1F"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdyuYgnk4voN"
      },
      "source": [
        "# **Arquitetura da Rede**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQNXrAvNHKWV"
      },
      "source": [
        "### *ConvNet 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgYicLymPIM6"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "\n",
        "def model_convnet2(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  # Image augmentation block\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  x = layers.Conv2D(32, kernel_size=(7,7),\n",
        "                    activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Conv2D(64, kernel_size=(5,5),\n",
        "                    activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(128, activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "\n",
        "  if num_classes == 2:\n",
        "    activation = \"sigmoid\"\n",
        "    units = 1\n",
        "  else:\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "  outputs = layers.Dense(units, activation=activation)(x)\n",
        "  return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BRnw-CP1Ca"
      },
      "source": [
        "### *ConvNet 3*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0t_mYqzHIy1"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "\n",
        "def model_convnet3(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  # Image augmentation block\n",
        "  data_aug = data_augmentation(inputs)\n",
        "\n",
        "  resc = layers.Rescaling(1./255) (data_aug)\n",
        "  conv_1 = layers.Conv2D(16, kernel_size=(7,7),\n",
        "                          padding='same', activation='relu')(resc)\n",
        "  max_1 = layers.MaxPooling2D()(conv_1)\n",
        "  conv_2 = layers.Conv2D(32, kernel_size=(5,5),\n",
        "                          padding='same', activation='relu')(max_1)\n",
        "  max_2 = layers.MaxPooling2D()(conv_2)\n",
        "  conv_3 = layers.Conv2D(64, kernel_size=(3,3),\n",
        "                          padding='same', activation='relu')(max_2)\n",
        "  max_3 = layers.MaxPooling2D()(conv_3)\n",
        "  flat = layers.Flatten()(max_3)\n",
        "  dropout = layers.Dropout(0.5)(flat)\n",
        "  dense = layers.Dense(128, activation='relu')(dropout)\n",
        "\n",
        "  if num_classes == 2:\n",
        "    activation = \"sigmoid\"\n",
        "    units = 1\n",
        "  else:\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "  outputs = layers.Dense(units, activation=activation)(dense)\n",
        "  return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V41RrWsMSDad"
      },
      "source": [
        "### *ResNet50*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xA6ASy_RXGy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "backend.clear_session()\n",
        "\n",
        "def model_resnet50(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  # Image augmentation block\n",
        "  data_aug = data_augmentation(inputs)\n",
        "\n",
        "  resize = layers.Resizing(224, 224) (data_aug)\n",
        "\n",
        "  if num_classes == 2:\n",
        "    activation = \"sigmoid\"\n",
        "    units = 1\n",
        "  else:\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "  outputs = ResNet50(include_top=True,\n",
        "                     weights=None,\n",
        "                     input_tensor=None,\n",
        "                     input_shape=None,\n",
        "                     pooling=None,\n",
        "                     classes=units,\n",
        "                     classifier_activation=activation)(resize)\n",
        "\n",
        "  return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43jaRfmrbMBT"
      },
      "source": [
        "### *VGG16*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p3j6yHRbMBV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "backend.clear_session()\n",
        "\n",
        "def model_vgg16(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  # Image augmentation block\n",
        "  data_aug = data_augmentation(inputs)\n",
        "\n",
        "  resize = layers.Resizing(224, 224) (data_aug)\n",
        "\n",
        "  if num_classes == 2:\n",
        "    activation = \"sigmoid\"\n",
        "    units = 1\n",
        "  else:\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "  outputs = VGG16(include_top=True,\n",
        "                  weights=None,\n",
        "                  input_tensor=None,\n",
        "                  input_shape=None,\n",
        "                  pooling=None,\n",
        "                  classes=units,\n",
        "                  classifier_activation=activation)(resize)\n",
        "\n",
        "  return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKUhp4av852I"
      },
      "source": [
        "### *LBP-CNN*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwAIBwfh852L"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "\n",
        "def LBPExtract(image):\n",
        "  paddings = tf.constant([[0,0],[1, 1], [1, 1]])\n",
        "  Im=tf.pad(image, paddings,\"CONSTANT\")\n",
        "  M=Im.shape [1]\n",
        "  N=Im.shape [2]\n",
        "\n",
        "  # Select the pixels of masks in the form of matrices\n",
        "  y00=Im[:,0:M-2, 0:N-2]\n",
        "  y01=Im[:,0:M-2, 1:N-1]\n",
        "  y02=Im[:,0:M-2, 2:N  ]\n",
        "  #\n",
        "  y10=Im[:,1:M-1, 0:N-2]\n",
        "  y11=Im[:,1:M-1, 1:N-1]\n",
        "  y12=Im[:,1:M-1, 2:N  ]\n",
        "  #\n",
        "  y20=Im[:,2:M, 0:N-2]\n",
        "  y21=Im[:,2:M, 1:N-1]\n",
        "  y22=Im[:,2:M, 2:N ]\n",
        "\n",
        "\n",
        "  # y00  y01  y02\n",
        "  # y10  y11  y12\n",
        "  # y20  y21  y22\n",
        "\n",
        "  # Comparisons\n",
        "  # 1 -----------------------------------------\n",
        "  g=tf.greater_equal(y01,y11)\n",
        "  z=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                tf.constant(1, dtype='uint8') )\n",
        "  # 2 -----------------------------------------\n",
        "  g=tf.greater_equal(y02,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(2, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 3 -----------------------------------------\n",
        "  g=tf.greater_equal(y12,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(4, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 4 -----------------------------------------\n",
        "  g=tf.greater_equal(y22,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(8, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 5 -----------------------------------------\n",
        "  g=tf.greater_equal(y21,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(16, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 6 -----------------------------------------\n",
        "  g=tf.greater_equal(y20,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(32, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 7 -----------------------------------------\n",
        "  g=tf.greater_equal(y10,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(64, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  # 8 -----------------------------------------\n",
        "  g=tf.greater_equal(y00,y11)\n",
        "  tmp=tf.multiply(tf.cast(g, dtype='uint8'),\n",
        "                  tf.constant(128, dtype='uint8') )\n",
        "  z =tf.add(z,tmp)\n",
        "  #--------------------------------------------\n",
        "  return tf.cast(z, dtype=tf.float32)\n",
        "\n",
        "def model_lbp_cnn(input_shape, num_classes):\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  data_aug = data_augmentation(inputs)\n",
        "  img_1 = layers.Lambda((lambda x: x[:,:,:,0]))(data_aug)\n",
        "  img_2 = layers.Lambda((lambda x: x[:,:,:,1]))(data_aug)\n",
        "  img_3 = layers.Lambda((lambda x: x[:,:,:,2]))(data_aug)\n",
        "\n",
        "  # Normal Path\n",
        "  data_1 = layers.Conv1D(32, kernel_size=3,\n",
        "                         activation=\"relu\")(img_1)\n",
        "  data_1 = layers.Conv1D(64, kernel_size=3,\n",
        "                         activation=\"relu\")(data_1)\n",
        "\n",
        "  data_2 = layers.Conv1D(32, kernel_size=3,\n",
        "                         activation=\"relu\")(img_2)\n",
        "  data_2 = layers.Conv1D(64, kernel_size=3,\n",
        "                         activation=\"relu\")(data_2)\n",
        "\n",
        "  data_3 = layers.Conv1D(32, kernel_size=3,\n",
        "                         activation=\"relu\")(img_3)\n",
        "  data_3 = layers.Conv1D(64, kernel_size=3,\n",
        "                         activation=\"relu\")(data_3)\n",
        "\n",
        "  data_dense = layers.concatenate(inputs=[data_1, data_2, data_3])\n",
        "  data_dense = layers.Dense(128, activation='relu')(data_dense)\n",
        "  data_dense = layers.Flatten()(data_dense)\n",
        "\n",
        "  # LBP Path\n",
        "  lbd_1 = layers.Lambda(LBPExtract)(img_1)\n",
        "  lbp_1 = layers.Conv1D(32, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_1)\n",
        "  lbp_1 = layers.Conv1D(64, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_1)\n",
        "\n",
        "  lbd_2 = layers.Lambda(LBPExtract)(img_2)\n",
        "  lbp_2 = layers.Conv1D(32, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_2)\n",
        "  lbp_2 = layers.Conv1D(64, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_2)\n",
        "\n",
        "  lbd_3 = layers.Lambda(LBPExtract)(img_3)\n",
        "  lbp_3 = layers.Conv1D(32, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_3)\n",
        "  lbp_3 = layers.Conv1D(64, kernel_size=3,\n",
        "                        activation=\"relu\")(lbd_3)\n",
        "\n",
        "  lbp = layers.concatenate(inputs=[lbd_1, lbd_2, lbd_3])\n",
        "  lbp = layers.Dense(128, activation='relu')(lbp)\n",
        "  lbp = layers.Flatten()(lbp)\n",
        "\n",
        "  # Concatena caminhos\n",
        "  concat = layers.concatenate(inputs=[data_dense, lbp])\n",
        "  concat = layers.Dense(256, activation='relu')(concat)\n",
        "\n",
        "  if num_classes == 2:\n",
        "      activation = \"sigmoid\"\n",
        "      units = 1\n",
        "  else:\n",
        "      activation = \"softmax\"\n",
        "      units = num_classes\n",
        "\n",
        "  outputs = layers.Dense(units, activation=activation)(concat)\n",
        "  return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZAuYkOtP3ws"
      },
      "source": [
        "# **Seleção da Rede**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FOUe_uy_O5u"
      },
      "outputs": [],
      "source": [
        "model = model_convnet2(input_shape=image_size + (3,), num_classes=2)\n",
        "# model = model_convnet3(input_shape=image_size + (3,), num_classes=2)\n",
        "# model = model_resnet50(input_shape=image_size + (3,), num_classes=2)\n",
        "# model = model_vgg16(input_shape=image_size + (3,), num_classes=2)\n",
        "# model = model_lbp_cnn(input_shape=image_size + (3,), num_classes=2)\n",
        "\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlNOWvdm3YQd"
      },
      "source": [
        "# **Treinamento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TrJgJtvoPVRK"
      },
      "outputs": [],
      "source": [
        "#@title ***Treinamento***\n",
        "checkpoint_filepath = '/content/content'\n",
        "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_filepath,\n",
        "#     save_weights_only=True,\n",
        "#     monitor='val_accuracy',\n",
        "#     mode='max',\n",
        "#     save_best_only=True)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0,\n",
        "    patience=20,\n",
        "    verbose=0,\n",
        "    restore_best_weights = True)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.008)\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "model.compile(optimizer= keras.optimizers.Adam(),\n",
        "              loss = 'BinaryCrossentropy',\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs = epochs,\n",
        "                    callbacks = [early_stop, lr_callback],\n",
        "                    validation_data = val_ds,\n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjdSqbGW4-TA"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnt1N9mi07Zh"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 30})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1m32n0il4sEs"
      },
      "outputs": [],
      "source": [
        "#@title ***Plot Resultados***\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs=range(len(acc))\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "ax[0].plot(acc, 'r', label=\"Treinamento: %0.4f\" %np.mean(acc[-20:]))\n",
        "ax[0].plot(val_acc, 'g', label=\"Validação: %0.4f\" %np.mean(val_acc[-20:]))\n",
        "ax[0].set_xlabel('Épocas')\n",
        "ax[0].set_title('Training and Validoation Accuracy')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(loss, 'r', label=\"Treinamento: %0.4f\" %np.mean(loss[-20:]))\n",
        "ax[1].plot(val_loss, 'g', label=\"Validação: %0.4f\" %np.mean(val_loss[-20:]))\n",
        "ax[1].set_xlabel('Épocas')\n",
        "ax[1].set_title('Training and Validation loss')\n",
        "ax[1].legend()\n",
        "\n",
        "print(\"Accuracy: \", np.mean(acc[-20:]), np.mean(val_acc[-20:]))\n",
        "print(\"Loss: \", np.mean(loss[-20:]), np.mean(val_loss[-20:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua8zfFvplkqU"
      },
      "source": [
        "# **Matriz de Confusão**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SA_vsv5--IyZ"
      },
      "outputs": [],
      "source": [
        "#@title ***Vetor de Teste***\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for data,label in test_ds:\n",
        "  predictions = model.predict(data)\n",
        "  y_true.append(label)\n",
        "\n",
        "\n",
        "  pred = tf.math.round(predictions)\n",
        "  y_pred.append(pred)\n",
        "\n",
        "y_pred = tf.concat(y_pred, axis=0)\n",
        "y_true = tf.concat(y_true, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thu0gHoPYtYG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ***Plot Matriz de Confusão***\n",
        "classes = (['Extração Ilegal', 'Extração Legal'])\n",
        "# classes = (['non-logging', 'selective-loggin'])\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "sns.set(font_scale=2.3) #for label size\n",
        "sns.heatmap(cm/cm.sum(axis=0), annot=True, annot_kws={\"size\": 30}, fmt='.2%',\n",
        "            cbar = False, cmap='Purples', xticklabels=classes, yticklabels=classes);\n",
        "ax.set_ylabel('Classificação Real',fontsize=30)\n",
        "ax.set_xlabel('Classificação Predita',fontsize=30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ohLa_Bxc3SRR",
        "Ypcd8Bj7yUe2",
        "e3VHWdLc3ah7",
        "ertFT1lWyUe7",
        "hkl-lGqQ2mFW",
        "4Yy0VNAxzuje",
        "3KEuu3gu2uQP",
        "N-kWhpSeRraI",
        "uFE-RdapAWmW",
        "3HfSSxLVCFfY",
        "2yzSB3Y6Jwy4",
        "2chJryzfCUop",
        "ztHR6tWL3gcY",
        "PdyuYgnk4voN",
        "kQNXrAvNHKWV",
        "V6BRnw-CP1Ca",
        "V41RrWsMSDad",
        "43jaRfmrbMBT",
        "uKUhp4av852I",
        "IjdSqbGW4-TA"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
